# data-engineering-standards
ðŸš‚ Data Engineering Standards

In this repository, I collect information about:

---

## Data Modeling:

- Understanding normalization, denormalization, and star/snowflake schemas.
- Familiarity with tools like dbt (Data Build Tool) for transformations.

---

## ETL/ELT Pipelines:

- Best practices for designing scalable pipelines (batch and stream processing).
- Tools: Apache Airflow, Dagster, Databricks.

---

## Big Data Frameworks:

- Distributed data processing standards: Apache Spark (use cases, DAGs), Hadoop.
- Query engines like Presto, Trino.

---

## Data Storage:

- Relational databases (SQL standards: ANSI SQL).
- NoSQL databases: MongoDB, Cassandra, DynamoDB.
- Cloud-based data warehouses: Snowflake, BigQuery, Redshift.

---

## Data Governance and Quality:

- Implementing data lineage, cataloging (e.g., Apache Atlas, DataHub).
- Ensuring data quality: Great Expectations, Deequ.
